{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These notebooks are supplemental to my main notebooks: 'topic_modeling_lotr_complete' & 'word2vec_lotr_complete'\n",
    "# Please see these notebooks for proper and comprehensive annotations. \n",
    "import os, glob, re, string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./the_lord_of_the_rings/the_fellowship_of_the_ring.txt', 'r') as file:\n",
    "    fellow = file.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984984"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk;\n",
    "from nltk.corpus import stopwords;\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer;\n",
    "from sklearn.decomposition import NMF;\n",
    "from sklearn.preprocessing import normalize;\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wars'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove punctuation and tokenize\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "fellow_tokens = tokenizer.tokenize(fellow)\n",
    "fellow_tokens[1971]\n",
    "\n",
    "# Keeping capitalization because I want the model to treat the proper nouns accordingly. Names are important in LotR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on previous models, it's imperative to add some stop words. \n",
    "# add stopwords - changing this list can have a dramatic effect on results in the LDA model because it uses word counts\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.append('said') # removed due to disproportional frequency\n",
    "stopwords.append('come')\n",
    "stopwords.append('came')\n",
    "\n",
    "# Additional stopwords, like proper names, could dramatically alter results. Keeping them to preserve the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Length of original list: 188191 words\n",
      "\n",
      "Length of list after stopwords removal: 86873 words\n"
     ]
    }
   ],
   "source": [
    "# Removes stopwords \n",
    "fellow_clean = [word for word in fellow_tokens if word.lower() not in stopwords]\n",
    "print(\"=\"*90)\n",
    "print(f'Length of original list: {len(fellow_tokens)} words\\n')\n",
    "print(f'Length of list after stopwords removal: {len(fellow_clean)} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fornost'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatize tokens.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "fellow_tokens_lems = [lemmatizer.lemmatize(i) for i in fellow_clean]\n",
    "fellow_tokens_lems[2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = WordNetLemmatizer()\n",
    "class LemmaCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(LemmaCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (lemm.lemmatize(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling our overwritten Count vectorizer\n",
    "tf_vectorizer = LemmaCountVectorizer(max_df=0.95, \n",
    "                                     min_df=2,\n",
    "                                     stop_words='english',\n",
    "                                     decode_error='ignore')\n",
    "tf = tf_vectorizer.fit_transform(fellow_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Our LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=11, max_iter=5,\n",
    "                                learning_method = 'online',\n",
    "                                learning_offset = 50.,\n",
    "                                random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=11, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to print top words\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for index, topic in enumerate(model.components_):\n",
    "        message = \"\\nTopic #{}:\".format(index)\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1 :-1]])\n",
    "        print(message)\n",
    "        print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model: \n",
      "\n",
      "Topic #0:aragorn tree boromir road hill stone company sun power west\n",
      "======================================================================\n",
      "\n",
      "Topic #1:like dark day way know hand say gimli left heart\n",
      "======================================================================\n",
      "\n",
      "Topic #2:ring light land thing little suddenly stood grey lay high\n",
      "======================================================================\n",
      "\n",
      "Topic #3:sam gandalf away went let black fear head soon world\n",
      "======================================================================\n",
      "\n",
      "Topic #4:frodo river thought boat end merry place enemy turned green\n",
      "======================================================================\n",
      "\n",
      "Topic #5:far water white seen deep spoke mr ore knew forward\n",
      "======================================================================\n",
      "\n",
      "Topic #6:shall hobbit pippin wind path answered gate going evil moria\n",
      "======================================================================\n",
      "\n",
      "Topic #7:time looked think good passed elrond shire folk sat star\n",
      "======================================================================\n",
      "\n",
      "Topic #8:long great elf night heard shadow mountain voice door fell\n",
      "======================================================================\n",
      "\n",
      "Topic #9:eye old saw word bilbo strider hope wood round grew\n",
      "======================================================================\n",
      "\n",
      "Topic #10:foot cried legolas right look dwarf men face wall moment\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 10\n",
    "print(\"\\nTopics in LDA model: \")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Our NMF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Negative Matrix Factorization in sklearn for comparison to LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CountVectorizer to get total word counts in documents\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", max_features = 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform words with TfidfTransformer - This takes into account term frequency across and within documents\n",
    "\n",
    "word_counts = vectorizer.fit_transform(fellow_tokens)\n",
    "\n",
    "tfidf_transform = TfidfTransformer(smooth_idf = False)\n",
    "\n",
    "words_tfidf = tfidf_transform.fit_transform(word_counts)\n",
    "\n",
    "# final_words = normalize(words_tfidf, norm = 'l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate NMF model and fit to tfidf transformed documents\n",
    "\n",
    "model = NMF(n_components = 10, init = 'nndsvd')\n",
    "\n",
    "# Set W as the document by topic matrix\n",
    "# Set H as the topic by word matrix\n",
    "\n",
    "W = model.fit_transform(words_tfidf)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign topic indices back to feature names - takes model, feature names from vectorizer, \n",
    "# and n_top_words as arguments. n_top_words selects the number of keywords per topic\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    lst = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        lst.append(message)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 3rd argument to number of topic keywords that are desired\n",
    "\n",
    "topics_nmf = (print_top_words(model, vectorizer.get_feature_names(), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Topic #0: the zvram forest foretelling foretell forests forester forestall foreseen forgave',\n",
       " 'Topic #1: and zvram forester forgave foretold foretelling foretell forests forestall forged',\n",
       " 'Topic #2: of you but for as had frodo with there we',\n",
       " 'Topic #3: to you but for as had frodo with there we',\n",
       " 'Topic #4: he you but for as had is at with frodo',\n",
       " 'Topic #5: in but his on is with frodo be all if',\n",
       " 'Topic #6: it you for as had at frodo we have all',\n",
       " 'Topic #7: that you but for as had said there with have',\n",
       " 'Topic #8: was his not is on at with were have their',\n",
       " 'Topic #9: they but his said is at with were him from']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check nmf topic assignment\n",
    "\n",
    "topics_nmf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
