{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re, string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Complete Lord of the Rings Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete texts of Lord of the Rings can be located at \n",
    "# 'https://archive.org/details/TheLordOfTheRing1TheFellowshipOfTheRing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./the_lord_of_the_rings/Lord_of_the_Rings_complete.txt', 'r') as file:\n",
    "    lotr = file.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2512368"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the size of the string to double check\n",
    "len(lotr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaving the corpus as one long string is optimal for NLP, LDA, and NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Text for NLP (Tokenize, Punctuation Removal, Stopwords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk;\n",
    "from nltk.corpus import stopwords;\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize\n",
    "\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer;\n",
    "\n",
    "# Please see my 'preprocessing_stopwords_plotly.ipynb' notebook for complete annotated preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation and tokenize\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "lotr_tokens = tokenizer.tokenize(lotr)\n",
    "\n",
    "# Keeping capitalization because I want the model to treat the proper nouns accordingly. Names are important in LotR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hobbits'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lotr_tokens[2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on previous models, it's imperative to add some stop words. \n",
    "# add stopwords - changing this list can have a dramatic effect on results in the LDA model because it uses word counts\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.append('said') # removed due to disproportional frequency\n",
    "stopwords.append('come')\n",
    "stopwords.append('came')\n",
    "\n",
    "# Additional stopwords, like proper names, could dramatically alter results. Keeping them to preserve the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Length of original list: 482056 words\n",
      "\n",
      "Length of list after stopwords removal: 221549 words\n"
     ]
    }
   ],
   "source": [
    "# Removes stopwords \n",
    "lotr_clean = [word for word in lotr_tokens if word.lower() not in stopwords]\n",
    "print(\"=\"*90)\n",
    "print(f'Length of original list: {len(lotr_tokens)} words\\n')\n",
    "print(f'Length of list after stopwords removal: {len(lotr_clean)} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flowers'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lotr_clean[1891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize tokens.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lotr_tokens_lems = [lemmatizer.lemmatize(i) for i in lotr_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flower'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lotr_tokens_lems[1891]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Lemmmatizing and CountVectorizer into one Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graciously borrowed from 'https://www.kaggle.com/meiyizi/spooky-nlp-and-topic-modelling-tutorial' \n",
    "# We have essentially inherited and subclassed the original Sklearn's CountVectorizer class \n",
    "# and overwritten the build_analyzer method by implementing the lemmatizer for each list in the raw text matrix.\n",
    "\n",
    "lemm = WordNetLemmatizer()\n",
    "class LemmaCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(LemmaCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (lemm.lemmatize(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling our overwritten Count vectorizer\n",
    "tf_vectorizer = LemmaCountVectorizer(max_df=0.95, \n",
    "                                     min_df=2,\n",
    "                                     stop_words='english',\n",
    "                                     decode_error='ignore')\n",
    "tf = tf_vectorizer.fit_transform(lotr_tokens_lems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Our LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.decomposition import NMF;\n",
    "from sklearn.preprocessing import normalize;\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Using the SKlearn LDA and NMF models -- The Gensim topic models produced uninterpreable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=21, max_iter=5,\n",
    "                                learning_method = 'online',\n",
    "                                learning_offset = 50.,\n",
    "                                random_state = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=2019, tm_mon=5, tm_mday=16, tm_hour=15, tm_min=47, tm_sec=56, tm_wday=3, tm_yday=136, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "lda.fit(tf)\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graciously borrowed from 'https://www.kaggle.com/meiyizi/spooky-nlp-and-topic-modelling-tutorial'\n",
    "# Define helper function to print top words\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for index, topic in enumerate(model.components_): # enumerate keeps count of iterations \n",
    "        message = \"\\nTopic #{}:\".format(index) \n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1 :-1]])\n",
    "        # list comprehension inside .join function\n",
    "        print(message)\n",
    "        print(\"=\"*70) # prints 70 '=' signs as separators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model: \n",
      "\n",
      "Topic #0:heard left took door enemy near fair darkness green began people son close short poor young bright unless room beast\n",
      "======================================================================\n",
      "\n",
      "Topic #1:hand road face head word look saruman evil lie tall star rock line evening elrond shape stream led standing bowed\n",
      "======================================================================\n",
      "\n",
      "Topic #2:merry city rider legolas rohan wish save boromir guess followed caught used running deed ship try strider tongue shagrat nearly\n",
      "======================================================================\n",
      "\n",
      "Topic #3:way little white soon fall mina help half taken run peril rising bank large forest escape huge afraid tunnel sighed\n",
      "======================================================================\n",
      "\n",
      "Topic #4:time looked tower lay thjoden hour pa grew sea answer bilbo valley come song stair hidden quickly big westward pain\n",
      "======================================================================\n",
      "\n",
      "Topic #5:high seen tell round felt better south captain looking silent earth trouble treebeard halted weary low bag bent father swift\n",
      "======================================================================\n",
      "\n",
      "Topic #6:far aragorn saw stone let suddenly east moment air river strength le asked cut cast kept worse tidings passing free\n",
      "======================================================================\n",
      "\n",
      "Topic #7:land night good hope set knew ground want walked told beregond beneath care living moon bridge bitter straight chapter fool\n",
      "======================================================================\n",
      "\n",
      "Topic #8:eye think heart grey dead year company ran arm new morning guard wild glad strong slope golden peace edge galadriel\n",
      "======================================================================\n",
      "\n",
      "Topic #9:sam long wall cried house place make coming leave clear cold sky lost return broken middle best body nice chance\n",
      "======================================================================\n",
      "\n",
      "Topic #10:day hobbit faramir gimli sun rode jomer sat denethor wonder news country ready bear turning meet broke citadel age shadowfax\n",
      "======================================================================\n",
      "\n",
      "Topic #11:foot mr fear gone battle maybe wood gave longer sight returned stay memory bore hall riding creature command remained dear\n",
      "======================================================================\n",
      "\n",
      "Topic #12:know horse elf rose red brought lady silver ago food mark sauron doom cotton bring wait cliff realm speed hardly\n",
      "======================================================================\n",
      "\n",
      "Topic #13:shall king tree mountain yes shire spoke rest horn smjagol step forth point burden secret vast quick muttered blade floor\n",
      "======================================================================\n",
      "\n",
      "Topic #14:away black passed gollum fell slowly field power hold sent bit grass tirith feel hurt mouth aside falling desire finger\n",
      "======================================================================\n",
      "\n",
      "Topic #15:like went old stood gate hill man wide strange pale heavy home filled use stand dwarf love opened counsel understand\n",
      "======================================================================\n",
      "\n",
      "Topic #16:men ring sword west speak world journey leaf cloak work fallen hard mean silence dream spring narrow gloom ill steward\n",
      "======================================================================\n",
      "\n",
      "Topic #17:dark master going water gondor folk got mind sleep sound host laid window eastward isengard sign mist known companion foe\n",
      "======================================================================\n",
      "\n",
      "Topic #18:pippin lord ore shadow deep north mordor answered small called forward cloud course open farewell lifted ahead till reached hole\n",
      "======================================================================\n",
      "\n",
      "Topic #19:great end turned wind path friend ride drew tale mile plain precious laughed life sprang remember swiftly climbed dim flame\n",
      "======================================================================\n",
      "\n",
      "Topic #20:frodo gandalf thing say light thought voice right need hear war held death turn doubt chief ere smoke forgotten lying\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 20\n",
    "print(\"\\nTopics in LDA model: \")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Our NMF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Negative Matrix Factorization comparison to LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CountVectorizer to get total word counts in documents\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", max_features = 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform words with TfidfTransformer - This takes into account term frequency across and within documents\n",
    "\n",
    "word_counts = vectorizer.fit_transform(lotr_tokens_lems)\n",
    "\n",
    "tfidf_transform = TfidfTransformer(smooth_idf = False)\n",
    "\n",
    "words_tfidf = tfidf_transform.fit_transform(word_counts)\n",
    "\n",
    "# final_words = normalize(words_tfidf, norm = 'l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25967035.137980964\n"
     ]
    }
   ],
   "source": [
    "# Instantiate NMF model and fit to tfidf transformed documents\n",
    "\n",
    "model = NMF(n_components = 50, init = 'nndsvd')\n",
    "\n",
    "# Set W as the document by topic matrix\n",
    "# Set H as the topic by word matrix\n",
    "\n",
    "W = model.fit_transform(words_tfidf)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign topic indices back to feature names - takes model, feature names from vectorizer, \n",
    "# and n_top_words as arguments. n_top_words selects the number of keywords per topic\n",
    "# renders differently than our previous function essentially does the same thing \n",
    "# Thanks to Nick Gayliard for inspiration \n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    lst = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        lst.append(message)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List numbered topic and top 10 words in the topic \n",
    "\n",
    "topics_nmf = (print_top_words(model, vectorizer.get_feature_names(), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Topic #0: frodo heard black good stone side left end passed made',\n",
       " 'Topic #1: sam heard ring stone side left made though lord much',\n",
       " 'Topic #2: great good shadow end think black foot left water king',\n",
       " 'Topic #3: could think stood black passed left voice hill white first',\n",
       " 'Topic #4: long shadow end heard foot water much lord gollum master',\n",
       " 'Topic #5: would shadow stone black passed voice let side king made',\n",
       " 'Topic #6: like heard hill king passed made let left going suddenly',\n",
       " 'Topic #7: gandalf end ever black foot stone passed left hill much',\n",
       " 'Topic #8: go good end stood shadow ever water side king lord',\n",
       " 'Topic #9: one end stood much voice hill water first face gate',\n",
       " 'Topic #10: back shadow stood think foot black side voice passed much',\n",
       " 'Topic #11: away good ever think foot though left hill first word',\n",
       " 'Topic #12: still ever heard think passed though hill much first white',\n",
       " 'Topic #13: see behind stone voice passed let black king hill master',\n",
       " 'Topic #14: many shadow end heard left foot stone water head take',\n",
       " 'Topic #15: upon good shadow end stone water heard side king much',\n",
       " 'Topic #16: time behind voice master white two wall face found get',\n",
       " 'Topic #17: far good shadow think ever side passed though water gollum',\n",
       " 'Topic #18: day stood shadow stone end black side king lord water',\n",
       " 'Topic #19: way good end ever heard side though stone water let',\n",
       " 'Topic #20: last shadow think passed left king suddenly word gollum found',\n",
       " 'Topic #21: dark behind passed voice left king much water master wall',\n",
       " 'Topic #22: men behind heard foot side though hill much lord first',\n",
       " 'Topic #23: yet behind end black voice water king white master two',\n",
       " 'Topic #24: know end heard stone left black voice king water much',\n",
       " 'Topic #25: hand ever foot shadow side though hill much first wall',\n",
       " 'Topic #26: eye think heard ever passed left gollum white going wall',\n",
       " 'Topic #27: well good behind water king let made lord gollum head',\n",
       " 'Topic #28: aragorn heard stone passed much going wall head first two',\n",
       " 'Topic #29: old think stood ever black side though left voice hill',\n",
       " 'Topic #30: went ever heard side much lord first master two wall',\n",
       " 'Topic #31: hobbit good shadow think side though first head gimli take',\n",
       " 'Topic #32: must behind good black stone side passed water king let',\n",
       " 'Topic #33: seemed good foot lord first word fell turned fire door',\n",
       " 'Topic #34: pippin shadow think good king made suddenly two head deep',\n",
       " 'Topic #35: shall stood passed voice side hill though much first wall',\n",
       " 'Topic #36: even behind stood voice passed king let water suddenly deep',\n",
       " 'Topic #37: may end stone heard left black water king much gollum',\n",
       " 'Topic #38: light behind foot side voice lord first master two face',\n",
       " 'Topic #39: thing heard ring stone ever hill made lord going wall',\n",
       " 'Topic #40: tree shadow think black side passed left much white face',\n",
       " 'Topic #41: road behind good end passed voice water much gollum two',\n",
       " 'Topic #42: looked stood foot voice king water gollum head suddenly found',\n",
       " 'Topic #43: merry black though left hill passed white master going face',\n",
       " 'Topic #44: say shadow think end ever heard stone water lord hill',\n",
       " 'Topic #45: little behind stone passed made king master suddenly first wall',\n",
       " 'Topic #46: thought good think king left water lord word suddenly face',\n",
       " 'Topic #47: land ring ever though stone hill much let water lord',\n",
       " 'Topic #48: night end think heard ever black left voice made much',\n",
       " 'Topic #49: saw ring behind good stood shadow end black ever foot']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check nmf topic assignment\n",
    "\n",
    "topics_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
