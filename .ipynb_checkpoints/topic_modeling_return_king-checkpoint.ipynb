{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These notebooks are supplemental to my main notebooks: 'topic_modeling_lotr_complete' & 'word2vec_lotr_complete'\n",
    "# Please see these notebooks for proper and comprehensive annotations. \n",
    "import os, glob, re, string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./the_lord_of_the_rings/the_return_of_king.txt', 'r') as file:\n",
    "    king = file.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710699"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(king)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk;\n",
    "from nltk.corpus import stopwords;\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer;\n",
    "from sklearn.decomposition import NMF;\n",
    "from sklearn.preprocessing import normalize;\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'battle'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove punctuation and tokenize\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "king_tokens = tokenizer.tokenize(king)\n",
    "king_tokens[1971]\n",
    "\n",
    "# Keeping capitalization because I want the model to treat the proper nouns accordingly. Names are important in LotR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on previous models, it's imperative to add some stop words. \n",
    "# add stopwords - changing this list can have a dramatic effect on results in the LDA model because it uses word counts\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.append('said') # removed due to disproportional frequency\n",
    "stopwords.append('come')\n",
    "stopwords.append('came')\n",
    "\n",
    "# Additional stopwords, like proper names, could dramatically alter results. Keeping them to preserve the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Length of original list: 137549 words\n",
      "\n",
      "Length of list after stopwords removal: 62349 words\n"
     ]
    }
   ],
   "source": [
    "king_clean = [word for word in king_tokens if word.lower() not in stopwords]\n",
    "print(\"=\"*90)\n",
    "print(f'Length of original list: {len(king_tokens)} words\\n')\n",
    "print(f'Length of list after stopwords removal: {len(king_clean)} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62349"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatize tokens.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "king_tokens_lems = [lemmatizer.lemmatize(i) for i in king_clean]\n",
    "len(king_tokens_lems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = WordNetLemmatizer()\n",
    "class LemmaCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(LemmaCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (lemm.lemmatize(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = LemmaCountVectorizer(max_df=0.95, \n",
    "                                     min_df=2,\n",
    "                                     stop_words='english',\n",
    "                                     decode_error='ignore')\n",
    "tf = tf_vectorizer.fit_transform(king_tokens_lems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=11, max_iter=5,\n",
    "                                learning_method = 'online',\n",
    "                                learning_offset = 50.,\n",
    "                                random_state = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
       "             n_components=11, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=2019, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to print top words\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for index, topic in enumerate(model.components_):\n",
    "        message = \"\\nTopic #{}:\".format(index)\n",
    "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1 :-1]])\n",
    "        print(message)\n",
    "        print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model: \n",
      "\n",
      "Topic #0:merry aragorn folk ruffian ring sword coming fair chief want\n",
      "======================================================================\n",
      "\n",
      "Topic #1:went gandalf pippin know going land black soon turned gondor\n",
      "======================================================================\n",
      "\n",
      "Topic #2:say way mr shire think left stone let head dead\n",
      "======================================================================\n",
      "\n",
      "Topic #3:frodo hobbit good shadow ore wall mordor sun field captain\n",
      "======================================================================\n",
      "\n",
      "Topic #4:thing city set faramir heard master high rose tell speak\n",
      "======================================================================\n",
      "\n",
      "Topic #5:day away old shall looked saw stood voice year face\n",
      "======================================================================\n",
      "\n",
      "Topic #6:like far eye little gate hope white heart fear look\n",
      "======================================================================\n",
      "\n",
      "Topic #7:end lord mountain tree right round new rohan suddenly hear\n",
      "======================================================================\n",
      "\n",
      "Topic #8:great hand dark passed rode grey seen better east sat\n",
      "======================================================================\n",
      "\n",
      "Topic #9:long time road got gone jowyn north place people friend\n",
      "======================================================================\n",
      "\n",
      "Topic #10:sam men king light thought house night took man battle\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 10\n",
    "print(\"\\nTopics in LDA model: \")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CountVectorizer to get total word counts in documents\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", max_features = 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform words with TfidfTransformer - This takes into account term frequency across and within documents\n",
    "\n",
    "word_counts = vectorizer.fit_transform(king_tokens)\n",
    "\n",
    "tfidf_transform = TfidfTransformer(smooth_idf = False)\n",
    "\n",
    "words_tfidf = tfidf_transform.fit_transform(word_counts)\n",
    "\n",
    "# final_words = normalize(words_tfidf, norm = 'l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate NMF model and fit to tfidf transformed documents\n",
    "\n",
    "model = NMF(n_components = 10, init = 'nndsvd')\n",
    "\n",
    "# Set W as the document by topic matrix\n",
    "# Set H as the topic by word matrix\n",
    "\n",
    "W = model.fit_transform(words_tfidf)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign topic indices back to feature names - takes model, feature names from vectorizer, \n",
    "# and n_top_words as arguments. n_top_words selects the number of keywords per topic\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    lst = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        lst.append(message)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 3rd argument to number of desired topic keywords \n",
    "\n",
    "topics_nmf = (print_top_words(model, vectorizer.get_feature_names(), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Topic #0: the gaffer foundering fount fountain fountains four fours fourteen fourteenth',\n",
       " 'Topic #1: and zirak fragrant fountain fountains four fours fourteen fourteenth fourth',\n",
       " 'Topic #2: of at is on there now were fount fowl foundering',\n",
       " 'Topic #3: to but they as with at is on be have',\n",
       " 'Topic #4: he his but they said not with as on now',\n",
       " 'Topic #5: in his for said not all there him from were',\n",
       " 'Topic #6: that but they his not as with on all be',\n",
       " 'Topic #7: it but they his as not with on had be',\n",
       " 'Topic #8: was his said for not as with all there is',\n",
       " 'Topic #9: you his for said at is there all had on']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
